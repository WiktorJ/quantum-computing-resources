## 06.10.2020

* Discriminator doesn't learn with too few layers. With two layers it was not able to distinguish between fixed real and fixed fake state. It is able to do so with 5 layers.


## 08.10.2020

* It seems that the label introduced by single rotation along $X$ axis is not enough to bring desired state information.
* The training regime should pick R or G at random, not first batch of R, then batch of G etc.
* How purity (or lack of it) of real input influence training? (Remember that $tr[p] = sum(\lambda) = 1$ and $tr[p^2] = sum(\lambda^2) \le 1$). How eigenvalues of real and generated state influence training.

### UNSUPERVISED AND SEMI-SUPERVISED LEARNING WITH CATEGORICAL GENERATIVE ADVERSARIAL NETWORKS

#### Discriminator

* We model the class information using Shannon entropy $H$ - expected value of the information carried by a sample from a given distribution. If we want $p(y|x,D)$ to be highly peaked (e.g. Gaussian bell with very low variance), which means low entropy. This is because, if $x$ belongs to class $k$, then all the elements drawn from conditional distribution should be similar.
* On the other hand, for $p(y| G(z), D)$ we want the entropy to be maximized. This will cause discriminator to be *uncertain* of class generated by the generator.

#### General objective

* Discriminator wants to maximize mutual information about data distribution and predicted class while minimizing information it encodes about $G(z)$.
* Generator wants to maximize mutual information between generated sample and predicted class distribution

## 12.10.2020

### Circuit-centric quantum classifiers

* It seems that strong (complete) entanglement is crucial for shallow circuit predictive power.
* Interesting view is to see a unitary (or a circuit moment) as a connection between two NN layers (p. 8).
* Interesting evaluation on how noise in the quantum device influence the classification results (p. 12).
* Possible takeaways that can be included in my research are:
    * Gradient calculation
    * Regularization (after the gradient base is extracted from quantum device)
    * Dropout
* Possible ways to reduce/translate circuit layout:
    * It is possible to decompose any gate $G$ to $Q^T D Q$, where $Q$ is another single qubit unitary and $D$ is diagonal.
    * With controlled $G$ - $C(G)$ - we can replace the "controlled part" by two phase gates for upper and lower qubit and decompose $G$ as above.

### Quantum machine learning in feature Hilbert spaces

This paper is exploring a link between SVM kernel methods and QML. The idea is that both of those techniques are leveraging high dimensional (infinite) Hilbert spaces to perform classification.

*In the quantum case, the kernel trick corresponds to changing the data encoding strategy*
